---
title: "My Model Selection in R Notes"
author: "Trenton Potgieter"
date: "Saturday, February 21, 2015"
output: html_document
---

## Overview

The data for this exercise will be from the __ISLR__ package, specifically the __Hitters__ dataset, which is the Major League Baseball Data for different Baseball players from the 1986 an 1987 sessions.

```{r packages, echo = TRUE}
# Load the required packages
require(ISLR)
require(leaps)
require(glmnet)

#View the data
summary(Hitters)

```

__Note__ from the summary that there is missing data, specifically in __Salary__ column. Therefore, before proceeding, we must remove the missing values as __Salary__ will be used as the response variable for the Regression Model. Although there are many ways to deal with Missing Values, for the sake of this exercise, we will take the easy way out and simply remove any row that has missing values.

```{r clean, echo = TRUE}
#View current amount of NA's in Salary
with(Hitters, sum(is.na(Salary)))

#Remove NA's in Salary
Hitters <- na.omit(Hitters)

#Confirm the NA's have been removed
with(Hitters, sum(is.na(Salary)))

```

# Best Subset Regression  
## Overview 

Best Subset Regression looks at all the possible regression models of differnt subsets of size and then looks for the best model of each size. It's output is a sequence of models, wich is the best for each particular size. The __leaps__ package allows this to be done compuationally in __R__, specifically the __regsubsets()__ function. 

## Finding the best model

```{r regfit, echo = TRUE}
#Execute the best subset regression with Salary as the response
regfit <- regsubsets(Salary~., data = Hitters)

#Summary
summary(regfit)

```

__Note__ that by default it gives the best-subsets up to size 8. Since we have 19 variables we execute the test with all variables.

```{r regfit.full, echo = TRUE}
#execute the best subset regression with Salary as the response and all 19 variables
regfit.full <- regsubsets(Salary~., data = Hitters, nvmax = 19)

#Summary
fit.summary <- summary(regfit.full)
fit.summary

#Plot CP Statistic 
plot(fit.summary$cp, xlab = "No. of Variables",
     ylab = "Estimate of Prediction Error (CP)")

```

__Note__ that the idea is to pick a model with the lowest __CP__ and as can be seen from the plot, the model with __10__ variables is the smallest. This can be verified by using the __which.min()__ function.  

Index of the smallest element of the CP component: __`r which.min(fit.summary$cp)`__


```{r point.plot, echo = TRUE}
#Redo the plot
plot(fit.summary$cp, xlab = "No. of Variables",
     ylab = "Estimate of Prediction Error (CP)")
#Highlite the point 10
points(10, fit.summary$cp[10], pch = 20, col = "red")

```

__Note__ that the __regsubsets()__ function has it's own, built-in plotting method. 

```{r regfit.plot, echo = TRUE}
#Plot using the regsubsets() plotting method
plot(regfit.full, scale = "Cp")

```

The plot above is a pattern picture where __Y Axis__ shows the __Cp Statistic__ where small is good, so __5__ corresponds to the model of size __10__. For each value, black squares indicate that the particular variable is "in" while the white squares indicate the particular variable is "out". __Note__ that "bad" cp's correspond to all models that have all the varbiables "in" or hardly any varibles "in".  

## Determining the coefficients

Having choosen model __10__, there is a method for __regsubsets()__ to display the coefficients of the particular model.

```{r coef, echo = TRUE}
#show the coefficients for model indexed 10
coef(regfit.full, 10)

```

# Forward Stepwise Selection
## Overview

Best Subset Regression is quite agressive in that it looks at ALL possible subsets, Forward Stepwise Selection on the other hand is a greedy algorithm in that each time it runs, it includes the next best variable BUT produces a nested sequence. Therefore it is a much "less adventurous" search, it just adds the next best variable tht fits the most. 

## Finding the best Model

Here we continue to use the __regsubsets()__ function, but we specify the __method = forward__ option.

```{r regfit.fwd, echo = TRUE}
#execute regsubsets() with forward option
regfit.fwd <- regsubsets(Salary~., data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)

```

__Note__ how the models that are selected are exactly nested. So each new model includes all the variables that were before plus one new one.

## Plotting the "CP Statistic"

```{r fwd.plot, echo = TRUE}
#plot the fit
plot(regfit.fwd, scale = "Cp")

```

__Note__ that the resulting plot looks very similar to what we saw with "Best Subsets" with the same structure around the small end.

# Model Selection using a Validation Set
## Overview

Here we pick a subset of the variables and put them asside to be used as a validation set and the rest will be used as a training data set. This way we can choose a good subset model. 

__Note: This approach is slightly different from the approach used in the Text Book.__

## Creating the Validation and Test Sets

Since there are __`r dim(Hitters)[1]`__ rows of data, we break it down into $\frac{2}{3}$ __Training__ and $\frac{1}{3}$ __Test__. So $\frac{2}{3}$ is approcimately __180__ observations.

```{r validation, echo = TRUE}
#Set the seed
set.seed(1)

#Create the Training set by taking a sample of size 180
train <- sample(seq(dim(Hitters)[1]), 180, replace = FALSE)

#Create the fit on the data indexed byt the rows in "train"
regfit.fwd <- regsubsets(Salary~., data = Hitters[train, ],
                         nvmax = 19, method = "forward")
```

## Making Predictions

Now we make predictions on the observations on the __Test__ set. Since we already know that there are __19__ subset models, we set up vectors to record the errors since there is no "predict" method available for __regsubsets()__.

```{r manual.predict, echo = TRUE}
#create the vector to record errors
errors <- rep(NA, 19)

#Create the "X" matrix corresponding to the validation dataset
x.test <- model.matrix(Salary~., data = Hitters[-train, ]) #Note -train

#Make the predictions for each model
for(i in 1:length(errors)){
        #Exctract the coefficients for each model of size id = i
        c <- coef(regfit.fwd, id = i)
        #Manual predictoin
        #The coefficient vector returns the subset of variables used in model i
        #Index ther names returned to get the right elements in x.text, the supbset
        #of colums in x.test that correspond to variables in the current coefficient
        #vector.
        pred <- x.test[, names(c)]%*%c #Matrix multiply these elements multiply by coef. vector
        #Populate the errors vector with the mean squared error
        errors[i] <- mean((Hitters$Salary[-train] - pred)^2)
}

#plot the root mean squared error
plot(sqrt(errors), ylab = "Root MSE", ylim = c(300, 400), pch = 19, type = "b")

```

__Note__ that the plot above is a plot of the validation error. The plot is slightly "jumpy", which idicates noise. The minimum error seems to be around __5__. The __10__ that we chose previously is a slightly higher then the minimum.

Next we overlay the Residual Sum of Squares on the same plot.


```{r RSS, echo = TRUE}
#Recreate the plot
plot(sqrt(errors), ylab = "Root MSE", ylim = c(300, 400), pch = 19, type = "b")

#add points for the RSS value for comparison less NULL Model
points(sqrt(regfit.fwd$rss[-1]/180), col = "blue", pch = 19, type = "b") #Note [-1]
legend("topright", legend = c("Training", "Validation"), col = c("blue", "black"), pch = 19)

```

__NOTE:__ When overlaying the __Residual Sum of Squares__ on the same plot, We remove the first model. This corresponds to the __NULL__ model which was not included in the manual prediction. Additionally, the __Residual Sum of Squares__ (as it must do), decreases because Forward Stepwise Selection includes that variable that improves the "fit" the most. So by definition it must decrease to show the improved __RSS__ on the training data. 

Since __regsubsets()__ doesn't inlude a __predict()__ method and since the process is manual, we will cerate a __predict()__ function to be used in the future. 

```{r predict, echo = TRUE}
predict.regsubsets <- function(object,newdata, id, ...){
    #Take the foirmula from initial call on the fitted model e.g. Salary~.
    form <- as.formula(object$call[[2]])
    #Create a matrix of the model
    m <- model.matrix(form, newdata)
    #Extract the coefficients
    c <- coef(object, id = id)
    #Perform the MAtrix Multiplication
    m[, names(c)]%*%c
}

```

# Model Selection by Cross-Validation 
## Overview
Cross-validation is one of the preferred methods for doing model selection. In this example, we will use 10-fold Cross-validation, where we take 10 samples, with each observation being assigned a fold number. Thus 10 folds.

## Model Fit and Predictions

```{r 10.fold, echo = TRUE}
#Set the seed
set.seed(11)

#Create the folds vector of 1 to 10, with the length equal to the number of row in Hitters
folds <- sample(rep(1:10, length = nrow(Hitters)))

#Display the random assignnment of folds to each of the observations in Hitters
folds
table(folds)

#Create the MAtrix to contain the cross-validatio errors (10 rows, 19 colums)
cv.errors <- matrix(NA, 10, 19)

#Double loop
for(k in 1:10){
    #Fit the regsubsets() model with Salary as a reponse and the training data is all the
    #observations whos fold id is not equal to k i.e. train on all the observations except
    #those in the kth fold.
    best.fit <- regsubsets(Salary~., data = Hitters[folds!=k, ], nvmax = 19, method = "forward")
    
    #Iterate through each of the subsets and use the predict() method to make predictions on 
    #the observations whose fold id is equal to k.
    
    ##########################################################################################
    # Note that the predict() function is called and not predict.regsubsets(), bcause this   #
    # was written in a way hat the generic predict() function uderstands. The first argument #
    # is best.bit, which is a regsubsets() object so the generic predict() funciton knows to #
    # find the method which is predict.regsubsets().                                         #
    ##########################################################################################
    for(i in 1:19){
    pred <- predict(best.fit, Hitters[folds == k, ], id = i)
    
    #Compute the Mean Squared Error of the predictions and assign it to the kth row of cv.errors
    cv.errors[k, i] <- mean((Hitters$Salary[folds == k] - pred)^2)
    
    }
}

```

## Process the output

To process the output, we create a matrix with the means of each column. __Remember__ that there are __10__ rows and each row was the Mean Squared Error for a particular fold, but we want to average those down each colums. Then use the square root to get the Root Mean Squared Error.

```{r rmse, echo = TRUE}
#Create the output matrix
rmse.cv <- sqrt(apply(cv.errors, 2, mean))

#Plot the result
plot(rmse.cv, pch = 19, type = "b")

```

__Note__ that the curve is quite as "jumpy" as the validation curve because this is averaged over the full training set, done fold by fold and then avergaed, so it's smoother. This seems to favor models of size __11__ or __12__.

# Ridge Regresson and Lasso 
## Overview

For this section we use the __glmnet__ package. This package is used for fitting __Ridge__ models, __Lasso__ models and a whole class of models in-between (__elasticnet__).  

__Note__ that __glmnet__ doesn't use a formaula language, so we are required to give it a matrix of predictors and a response vector which need to be created.

```{r pre-req, echo = TRUE}
#Create x as the predictor matrix
x <- model.matrix(Salary~. -1, data = Hitters)

#Create y as the response vector
y <- Hitters$Salary

```

## Fit a Ridge Regression Model

The fist model we will fit it the __Ridge Regression Model__. This is achieved by calling __glmnet__ with __alpha = 0__, which is the __Ridge__, while __alpha = 1__ is the __Lasso__. (See the help file). 

__Note:__ For alpha's between __0__ and __1__ you get elastic net models, in-between __Ridge__ and __Lasso__. There is also a __cv.glmnet()__ function that will do cross-validation.

```{r fit.ridge, echo = TRUE}
#Fit the Ridge Model
fit.ridge <- glmnet(x, y, alpha = 0)

#Plot the fit
plot(fit.ridge, xvar = "lambda", label = TRUE)

```

The above is a plot as a function of log of lambda and the coefficients. __Ridge Regression__ is penalizefd by the __Sum of Squares__ of the coefficients, basivally penalties put on the sum of square of the coefficients which is controlled by the parameter lambda. So the criteria for __Ridge Regression__ is:

$RSS+\Lambda\sum\limits_{j=1}^p\beta_{j}^2$

So it's trying to minimize the __Residual Sum of Squares__, BUT its been modified by a penalty of the __Sum of Squares__ of the coefficients. So if lambda is big, we want the sum of squares of the coefficients to be small so that it shrinks the coefficients towards zero. As lambda gets very big, the coefficients will all be zero.

So what __glmnet__ does is it develops a whole path of models on a grid of values of lambda (about 100 values of lambda). So from the plot, when the log of lambda is __12__, all the coefficients are essentially zero. As we relax lambda, the coefficients grow away from zero (in a smooth way) and teh sum of squares of the coefficients get bigger until we reach a point where lambda is effectivkey zero and the coefficients are unregularized.

Unlike __Best Subset__ and __Forward Step-wise__ regression, which controls the complexit of a model by resttricting the number of variables, __Ridge Regression__ keeps all the variables in and shrinks the coefficients toward zero. 