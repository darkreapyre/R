---
title: "Regression Models - Week 1 Notes"
author: "Trenton Potgieter"
date: "Monday, April 06, 2015"
output: 
    pdf_document:
        toc: true
        latex_engine: xelatex
    fontsize: 11pt
    geometry: margin=1in
---

\newpage

# Introduction

## Background 

Data first used by Francis Galton, who created the terms __Regression__ and __Correlation__ in 1885. And by making use of __Rgression__, we are provided with very interpretable models.

```{r galton, echo = TRUE}
require(UsingR)

#Load the Data
data(galton)

#Plot the Child and parent data
par(mfrow = c(1, 2))
hist(galton$child, col = "blue", breaks = 100) #100 histogram breaks
hist(galton$parent, col = "blue", breaks = 100) #100 histogram breaks

```

The plots above do not descibe the joint relationship. To uderstand the joint relationship we need to first understand summarizing the __marginal__. The marginal is the distribution (on the histograms) of __Children__, disregarding __Parents__ and the distibution of __Parents__, disregarding __Children__, so summarizing the marginal informaion in each Histogram by themselves is a way of describing the "middle" of these datasets.

To do this, let's consider the __children's heights__. So let $Y_i$ be the height of a particular __child__ $i$ for $i=1,\ldots,n$, where $n=928$ (the number of __Children__).

So to define the middle we look for the value of $\mu$ that mimimizes $$\sum_{i=1}^n(Y_i -\mu)^2$$

__The sum of the squared distances between the data and the "middle" value.__

This turns out to be the center of mass of the histogram, the point that mimimizes the average squared distance from all the other points (Least Squares). So in this case the answer is the __sample mean__ or $\mu=\bar{X}$.

Remember that in Statistics, $\bar{X}$ is the __sample mean__ and $\mu$ is the __population mean__.

## Proof 

To prove this we will use the `manipulate()` function in `R` to se what value of $\mu$ minimizes the sum of squared deviations. (For mathematical proof, see Appendix A)

```{r manipulate, echo = TRUE}
require(manipulate)

#Create the Hist() Function
Hist <- function(mu){        
        #Create a histogram of the child data as before
        hist(galton$child, col = "blue", breaks = 100)
        #Draw the line that can be used by manipulate
        lines(c(mu, mu), c(0, 150), col = "red", lwd = 5)
        #Clculate the mean squared error
        mse <- mean((galton$child - mu)^2)
        #Create the labels
        text(63, 150, paste("mu = ", mu))
        text(63, 140, paste("MSE = ", round(mse, 2)))
}

#To call this and use manipulate in R, simply run the following:
#manipulate(Hist(mu), mu = slider(62, 74, step = 0.5))

```

So even though this can be seen visually, by using the `manipulate()` function and manually moving around the "red line", to find the exact optimal place that will balance out the Histogram.

Below is the actualy Histrogram of the __Empirical Mean__ of __`r mean(galton$child)`__.

```{r empirical, echo = TRUE}
#Plot the Empirical Mean
hist(galton$child, col = "blue", breaks = 100)
mean.child <- mean(galton$child)
lines(rep(mean.child, 100), seq(0, 150, length = 100), col = "red", lwd = 5)

```

## Comparing Children's Heights vs. Parebt's Heights

### Objective 

Doing this comparision is the heart of regression, basically how do we draw a line through Galton's Data as the following example plot shows:

__NOTE:__ Size of the points represents number of points at the (X, Y) combination. Additionally the regression line is centered through the average value.

```{r comparison, echo = TRUE}
#Create the X and Y Coordinates
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)

#Capture the frequency of each occurance 
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")

#Fit a basic Linear Model using lm()
fit <- lm(y~x, data = freqData)

#Plot the data and linear fit
plot(
    as.numeric(as.vector(freqData$parent)),
    as.numeric(as.vector(freqData$child)),
    pch = 21, col = "black", bg = "lightblue",
    cex = .15 * freqData$freq,
    xlab = "parent",
    ylab = "child"
    )
    abline(fit[1], fit[2], col = "red", lwd = 2)

```

__NOTE:__ To better illustrate the impact that the least squares criteria has on the graph (using the `manipulate()` function, see Appendix B). 

### Solution

As can be seen from the plot, we have fit a linear model to the data, basically by using the following:

```{r slope, echo = TRUE}
slope <- lm(I(child - mean(child))~I(parent - mean(parent)) -1, data = galton)
slope
```

This produces the value that minimizes the least squares criteria: __0.646__

The rest of this document will show __how__ to the solution automatically and also __why__ this is the solution. 

# Basic Notation and Definitions



\newpage

#Appendix A: Mathematical Proof for Least Squares

$$
 \begin{aligned}
 \sum_{i=1}^n \left(Y_i - \mu\right)^2 & = \
 \sum_{i=1}^n \left(Y_i - \bar Y + \bar Y - \mu\right)^2 \\
 & = \sum_{i=1}^n \left(Y_i - \bar Y \right)^2 + \
 2 \sum_{i=1}^n \left(Y_i - \bar Y \right) \left(\bar Y - \mu\right) + \
 \sum_{i=1}^n \left(\bar Y - \mu\right)^2 \\
 & = \sum_{i=1}^n \left(Y_i - \bar Y \right)^2 + \
 2 \left(\bar Y - \mu\right) \sum_{i=1}^n \left(Y_i - \bar Y \right) + \
 \sum_{i=1}^n \left(\bar Y - \mu\right)^2 \\
 & = \sum_{i=1}^n \left(Y_i - \bar Y \right)^2 + \
 2 \left(\bar Y - \mu\right) \left(\left(\sum_{i=1}^n Y_i\right) - \
 n \bar Y\right) + \
 \sum_{i=1}^n \left(\bar Y - \mu\right)^2 \\
 & = \sum_{i=1}^n \left(Y_i - \bar Y \right)^2 + \
 \sum_{i=1}^n \left(\bar Y -\mu\right)^2\\
 & \geq \sum_{i=1}^n \left(Y_i - \bar Y\right)^2 \
 \end{aligned}
$$

\newpage

#Appendix B: Using `manipulate()` to show Least Squares

```{r B, echo = TRUE}
require(manipulate)
myPlot <- function(beta){
    y <- galton$child - mean(galton$child)
    x <- galton$parent - mean(galton$parent)
    freqData <- as.data.frame(table(x, y))
    names(freqData) <- c("child", "parent", "freq")
    plot(
        as.numeric(as.vector(freqData$parent)),
        as.numeric(as.vector(freqData$child)),
        pch = 21, col = "black", bg = "lightblue",
        cex = .15 * freqData$freq,
        xlab = "Parent",
        ylab = "Child"
        )
    abline(0, beta, lwd = 3)
    points(0, 0, cex = 2, pch = 19)
    mse <- mean((y - beta * x)^2)
    title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}

#To execute, load the following using manipulate()
#manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))

```